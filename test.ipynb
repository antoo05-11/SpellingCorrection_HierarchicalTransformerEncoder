{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T14:12:18.680198Z",
     "start_time": "2024-04-06T14:12:18.673190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from Config import Config\n",
    "\n",
    "config = Config()"
   ],
   "id": "b174dea5b591cfc7",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T14:12:23.090655Z",
     "start_time": "2024-04-06T14:12:18.681773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "data = pd.read_csv('data/vi_processed.csv')\n",
    "\n",
    "correct_texts = []\n",
    "error_texts = []\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    if len(correct_texts) == 100: break\n",
    "    correct_texts.append(row.correct_text)\n",
    "    error_texts.append(row.error_text)\n",
    "\n",
    "correct_texts = correct_texts[:config.NUM_OF_INPUTS]\n",
    "error_texts = error_texts[:config.NUM_OF_INPUTS]"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-06 21:12:19.091833: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-06 21:12:19.101784: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-06 21:12:19.133730: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-06 21:12:19.134363: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-06 21:12:19.888610: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "word_level_tokenizer = Tokenizer(num_words=config.VOCAB_SIZE, oov_token='<UNK>', lower=True, split=' ', )\n",
    "\n",
    "word_unk_level_tokenizer = Tokenizer(oov_token='<UNK>', lower=True, split=' ', )\n",
    "\n",
    "character_level_tokenizer = Tokenizer(num_words=config.CHARACTER_VOCAB_SIZE, lower=True, char_level=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T14:12:23.129613Z",
     "start_time": "2024-04-06T14:12:23.091517Z"
    }
   },
   "id": "b3752f20d0d04fc5",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "word_level_tokenizer.fit_on_texts(correct_texts)\n",
    "word_unk_level_tokenizer.fit_on_texts(error_texts)\n",
    "character_level_tokenizer.fit_on_texts(error_texts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T14:12:23.145071Z",
     "start_time": "2024-04-06T14:12:23.130671Z"
    }
   },
   "id": "da68b19fddda92a7",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "input_sequences = word_level_tokenizer.texts_to_sequences(error_texts)\n",
    "output_sequences = word_level_tokenizer.texts_to_sequences(correct_texts)\n",
    "unk_input_sequences = word_unk_level_tokenizer.texts_to_sequences(error_texts)\n",
    "\n",
    "# Get character-level words lengths.\n",
    "input_words_lengths = []\n",
    "\n",
    "# Get character-level sequences.\n",
    "character_level_input_sequences = []\n",
    "\n",
    "for sequence in unk_input_sequences:\n",
    "    character_level_input_sequence = []\n",
    "    words_lengths = []\n",
    "    for word_token in sequence:\n",
    "        word = word_unk_level_tokenizer.index_word[word_token]\n",
    "        word = character_level_tokenizer.texts_to_sequences(word)\n",
    "        word_chars = [each[0] for each in word]\n",
    "        character_level_input_sequence.append(word_chars)\n",
    "        words_lengths.append((len(word_chars) if len(word_chars) <= config.MAX_WORD_LENGTH\n",
    "                              else config.MAX_WORD_LENGTH))\n",
    "\n",
    "    # Add padding for each word.\n",
    "    character_level_input_sequence = pad_sequences(character_level_input_sequence, maxlen=config.MAX_WORD_LENGTH,\n",
    "                                                   padding='post', truncating='post')\n",
    "\n",
    "    character_level_input_sequences.append(character_level_input_sequence)\n",
    "\n",
    "    input_words_lengths.append(words_lengths)\n",
    "\n",
    "# Get word-level sentences lengths.\n",
    "input_sentences_lengths = []\n",
    "for sequence in input_sequences: input_sentences_lengths.append(\n",
    "    (len(sequence) if len(sequence) <= config.MAX_SENTENCE_LENGTH\n",
    "     else config.MAX_SENTENCE_LENGTH))\n",
    "\n",
    "# Add padding for each.\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=config.MAX_SENTENCE_LENGTH, padding='post', truncating='post')\n",
    "output_sequences = pad_sequences(output_sequences, maxlen=config.MAX_SENTENCE_LENGTH, padding='post', truncating='post')\n",
    "character_level_input_sequences = pad_sequences(character_level_input_sequences, maxlen=config.MAX_SENTENCE_LENGTH,\n",
    "                                                padding='post', truncating='post')\n",
    "input_words_lengths = pad_sequences(input_words_lengths, maxlen=config.MAX_SENTENCE_LENGTH, padding='post',\n",
    "                                    truncating='post')\n",
    "\n",
    "input_sequences_np = np.array(input_sequences)\n",
    "character_level_input_sequences_np = np.array(character_level_input_sequences)\n",
    "output_sequences_np = np.array(output_sequences)\n",
    "\n",
    "input_words_lengths_np = np.array(input_words_lengths)\n",
    "input_sentences_lengths_np = np.array(input_sentences_lengths)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T14:12:23.172512Z",
     "start_time": "2024-04-06T14:12:23.146724Z"
    }
   },
   "id": "40b825572d89fe75",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": "(input_sentences_lengths[0])",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T14:12:23.178162Z",
     "start_time": "2024-04-06T14:12:23.173547Z"
    }
   },
   "id": "1d73054d0b834a9f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "# def prepare_batch(input, output):\n",
    "#     word_level_input = word_level_tokenizer.texts_to_sequences(input)\n",
    "#     word_level_input = tf.ragged.constant(word_level_input)\n",
    "#     word_level_input = word_level_input[:, :MAX_WORD_LEVEL_TOKENS]\n",
    "#     word_level_input = word_level_input.to_tensor()\n",
    "# \n",
    "#     unk_input_sequences = word_unk_level_tokenizer.texts_to_sequences(input)\n",
    "#     character_level_input_sequences = []\n",
    "# \n",
    "#     for sequence in unk_input_sequences:\n",
    "#         character_level_input_sequence = []\n",
    "#         for word_token in sequence:\n",
    "#             word = word_unk_level_tokenizer.index_word[word_token]\n",
    "#             word = character_level_tokenizer.texts_to_sequences(word)\n",
    "#             word_chars = [each[0] for each in word]\n",
    "#             character_level_input_sequence.append(word_chars)\n",
    "#         character_level_input_sequence = tf.ragged.constant(character_level_input_sequence)\n",
    "#         character_level_input_sequence = character_level_input_sequence[\n",
    "#                                          :MAX_SENTENCE_LENGTH,\n",
    "#                                          :MAX_WORD_LENGTH]\n",
    "#         character_level_input_sequence = character_level_input_sequence.to_tensor()\n",
    "#         character_level_input_sequences.append(character_level_input_sequence)\n",
    "# \n",
    "#     print(character_level_input_sequences)\n",
    "#     character_level_input_sequences = tf.ragged.constant(character_level_input_sequences)\n",
    "# \n",
    "#     output = word_level_tokenizer.texts_to_sequences(output)\n",
    "#     output = tf.ragged.constant(output)\n",
    "#     output = output[:, :MAX_SENTENCE_LENGTH]\n",
    "#     output = output.to_tensor()\n",
    "# \n",
    "#     return (word_level_input, character_level_input_sequences), output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T14:12:23.186680Z",
     "start_time": "2024-04-06T14:12:23.179050Z"
    }
   },
   "id": "23d34deb433228db",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "from HierarchicalTransformerEncoder import HierarchicalTransformerEncoder\n",
    "\n",
    "model = HierarchicalTransformerEncoder(num_character_level_layers=config.NUM_CHARACTER_LEVEL_LAYERS,\n",
    "                                       num_word_level_layers=config.NUM_WORD_LEVEL_LAYERS,\n",
    "                                       character_level_d_model=config.CHARACTER_LEVEL_D_MODEL,\n",
    "                                       word_level_d_model=config.WORD_LEVEL_D_MODEL,\n",
    "                                       num_heads=config.NUM_HEADS, dff=config.DFF,\n",
    "                                       max_word_length=config.MAX_WORD_LENGTH,\n",
    "                                       max_sentence_length=config.MAX_SENTENCE_LENGTH,\n",
    "                                       vocab_size=config.VOCAB_SIZE,\n",
    "                                       character_vocab_size=config.CHARACTER_VOCAB_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T14:12:23.314987Z",
     "start_time": "2024-04-06T14:12:23.187721Z"
    }
   },
   "id": "7588ce8d87f47c5b",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T14:12:23.353912Z",
     "start_time": "2024-04-06T14:12:23.315896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from CustomSchedule import CustomSchedule\n",
    "\n",
    "learning_rate = CustomSchedule(config.WORD_LEVEL_D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)"
   ],
   "id": "58c4565b240a0060",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# word_input_shape = (config.BATCH_SIZE, config.MAX_SENTENCE_LENGTH)\n",
    "# char_input_shape = (config.BATCH_SIZE, config.MAX_SENTENCE_LENGTH, config.MAX_WORD_LENGTH)\n",
    "# \n",
    "# model.build(input_shape=[word_input_shape, char_input_shape])\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    print('Find loss:')\n",
    "    print(\"Shape y_true:\", y_true[0].shape)\n",
    "    print(\"Shape y_pred:\", y_pred[0].shape)\n",
    "    softmax_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)(y_true[0], y_pred[0])\n",
    "    print('loss = ', softmax_loss)\n",
    "    # sigmoid_loss = tf.keras.losses.BinaryCrossentropy(from_logits=False)(y_true, y_pred[1])\n",
    "    total_loss = softmax_loss\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=custom_loss, metrics=['acc'])\n",
    "# model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T14:12:23.366827Z",
     "start_time": "2024-04-06T14:12:23.354750Z"
    }
   },
   "id": "19369c0f61882e99",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T14:12:23.371292Z",
     "start_time": "2024-04-06T14:12:23.368134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(input_sequences_np.shape)\n",
    "print(input_sentences_lengths_np.shape)\n",
    "print(character_level_input_sequences_np.shape)\n",
    "print(input_words_lengths_np.shape)"
   ],
   "id": "157023b3f1b53643",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 40)\n",
      "(100,)\n",
      "(100, 40, 10)\n",
      "(100, 40)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ffb0038c5420ac9b"
  },
  {
   "cell_type": "code",
   "source": [
    "model.fit(\n",
    "    [[input_sequences_np, input_sentences_lengths_np], [character_level_input_sequences_np, input_words_lengths_np]],\n",
    "    output_sequences_np, epochs=config.EPOCHS,\n",
    "    batch_size=config.BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T14:12:38.178065Z",
     "start_time": "2024-04-06T14:12:23.372263Z"
    }
   },
   "id": "d959e3830400be73",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Shape của word_embedding_outputs: (50, 40, 128)\n",
      "WARNING:tensorflow:From /home/thanhan/.local/lib/python3.10/site-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "Shape của correction_output: (50, 40, 10000)\n",
      "Shape của detection_output: (50, 40)\n",
      "Find loss:\n",
      "Shape y_true: (40,)\n",
      "Shape y_pred: (40, 10000)\n",
      "loss =  Tensor(\"custom_loss/sparse_categorical_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/encoder_layer_1/query/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/encoder_layer_1/query/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/encoder_layer_1/key/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/encoder_layer_1/key/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/encoder_layer_1/value/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/encoder_layer_1/value/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/encoder_layer_1/attention_output/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/encoder_layer_1/attention_output/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/layer_normalization_6/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/layer_normalization_6/beta:0', 'dense_6/kernel:0', 'dense_6/bias:0', 'dense_7/kernel:0', 'dense_7/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/feed_forward_3/layer_normalization_7/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/feed_forward_3/layer_normalization_7/beta:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/encoder_layer_2/query/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/encoder_layer_2/query/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/encoder_layer_2/key/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/encoder_layer_2/key/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/encoder_layer_2/value/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/encoder_layer_2/value/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/encoder_layer_2/attention_output/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/encoder_layer_2/attention_output/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/layer_normalization_8/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/layer_normalization_8/beta:0', 'dense_8/kernel:0', 'dense_8/bias:0', 'dense_9/kernel:0', 'dense_9/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/feed_forward_4/layer_normalization_9/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/feed_forward_4/layer_normalization_9/beta:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/encoder_layer_3/query/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/encoder_layer_3/query/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/encoder_layer_3/key/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/encoder_layer_3/key/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/encoder_layer_3/value/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/encoder_layer_3/value/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/encoder_layer_3/attention_output/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/encoder_layer_3/attention_output/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/layer_normalization_10/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/layer_normalization_10/beta:0', 'dense_10/kernel:0', 'dense_10/bias:0', 'dense_11/kernel:0', 'dense_11/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/feed_forward_5/layer_normalization_11/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/feed_forward_5/layer_normalization_11/beta:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/encoder_layer_4/query/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/encoder_layer_4/query/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/encoder_layer_4/key/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/encoder_layer_4/key/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/encoder_layer_4/value/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/encoder_layer_4/value/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/encoder_layer_4/attention_output/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/encoder_layer_4/attention_output/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/layer_normalization_12/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/layer_normalization_12/beta:0', 'dense_12/kernel:0', 'dense_12/bias:0', 'dense_13/kernel:0', 'dense_13/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/feed_forward_6/layer_normalization_13/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/feed_forward_6/layer_normalization_13/beta:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/encoder_layer_5/query/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/encoder_layer_5/query/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/encoder_layer_5/key/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/encoder_layer_5/key/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/encoder_layer_5/value/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/encoder_layer_5/value/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/encoder_layer_5/attention_output/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/encoder_layer_5/attention_output/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/layer_normalization_14/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/layer_normalization_14/beta:0', 'dense_14/kernel:0', 'dense_14/bias:0', 'dense_15/kernel:0', 'dense_15/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/feed_forward_7/layer_normalization_15/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/feed_forward_7/layer_normalization_15/beta:0', 'hierarchical_transformer_encoder/detection_layer/kernel:0', 'hierarchical_transformer_encoder/detection_layer/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/encoder_layer_1/query/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/encoder_layer_1/query/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/encoder_layer_1/key/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/encoder_layer_1/key/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/encoder_layer_1/value/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/encoder_layer_1/value/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/encoder_layer_1/attention_output/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/encoder_layer_1/attention_output/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/layer_normalization_6/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/layer_normalization_6/beta:0', 'dense_6/kernel:0', 'dense_6/bias:0', 'dense_7/kernel:0', 'dense_7/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/feed_forward_3/layer_normalization_7/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/feed_forward_3/layer_normalization_7/beta:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/encoder_layer_2/query/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/encoder_layer_2/query/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/encoder_layer_2/key/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/encoder_layer_2/key/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/encoder_layer_2/value/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/encoder_layer_2/value/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/encoder_layer_2/attention_output/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/encoder_layer_2/attention_output/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/layer_normalization_8/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/layer_normalization_8/beta:0', 'dense_8/kernel:0', 'dense_8/bias:0', 'dense_9/kernel:0', 'dense_9/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/feed_forward_4/layer_normalization_9/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/feed_forward_4/layer_normalization_9/beta:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/encoder_layer_3/query/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/encoder_layer_3/query/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/encoder_layer_3/key/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/encoder_layer_3/key/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/encoder_layer_3/value/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/encoder_layer_3/value/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/encoder_layer_3/attention_output/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/encoder_layer_3/attention_output/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/layer_normalization_10/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/layer_normalization_10/beta:0', 'dense_10/kernel:0', 'dense_10/bias:0', 'dense_11/kernel:0', 'dense_11/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/feed_forward_5/layer_normalization_11/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/feed_forward_5/layer_normalization_11/beta:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/encoder_layer_4/query/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/encoder_layer_4/query/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/encoder_layer_4/key/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/encoder_layer_4/key/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/encoder_layer_4/value/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/encoder_layer_4/value/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/encoder_layer_4/attention_output/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/encoder_layer_4/attention_output/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/layer_normalization_12/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/layer_normalization_12/beta:0', 'dense_12/kernel:0', 'dense_12/bias:0', 'dense_13/kernel:0', 'dense_13/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/feed_forward_6/layer_normalization_13/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/feed_forward_6/layer_normalization_13/beta:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/encoder_layer_5/query/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/encoder_layer_5/query/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/encoder_layer_5/key/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/encoder_layer_5/key/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/encoder_layer_5/value/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/encoder_layer_5/value/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/encoder_layer_5/attention_output/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/encoder_layer_5/attention_output/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/layer_normalization_14/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/layer_normalization_14/beta:0', 'dense_14/kernel:0', 'dense_14/bias:0', 'dense_15/kernel:0', 'dense_15/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/feed_forward_7/layer_normalization_15/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/feed_forward_7/layer_normalization_15/beta:0', 'hierarchical_transformer_encoder/detection_layer/kernel:0', 'hierarchical_transformer_encoder/detection_layer/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "Shape của word_embedding_outputs: (50, 40, 128)\n",
      "Shape của correction_output: (50, 40, 10000)\n",
      "Shape của detection_output: (50, 40)\n",
      "Find loss:\n",
      "Shape y_true: (40,)\n",
      "Shape y_pred: (40, 10000)\n",
      "loss =  Tensor(\"custom_loss/sparse_categorical_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/encoder_layer_1/query/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/encoder_layer_1/query/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/encoder_layer_1/key/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/encoder_layer_1/key/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/encoder_layer_1/value/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/encoder_layer_1/value/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/encoder_layer_1/attention_output/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/encoder_layer_1/attention_output/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/layer_normalization_6/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/layer_normalization_6/beta:0', 'dense_6/kernel:0', 'dense_6/bias:0', 'dense_7/kernel:0', 'dense_7/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/feed_forward_3/layer_normalization_7/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/feed_forward_3/layer_normalization_7/beta:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/encoder_layer_2/query/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/encoder_layer_2/query/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/encoder_layer_2/key/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/encoder_layer_2/key/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/encoder_layer_2/value/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/encoder_layer_2/value/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/encoder_layer_2/attention_output/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/encoder_layer_2/attention_output/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/layer_normalization_8/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/layer_normalization_8/beta:0', 'dense_8/kernel:0', 'dense_8/bias:0', 'dense_9/kernel:0', 'dense_9/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/feed_forward_4/layer_normalization_9/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/feed_forward_4/layer_normalization_9/beta:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/encoder_layer_3/query/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/encoder_layer_3/query/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/encoder_layer_3/key/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/encoder_layer_3/key/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/encoder_layer_3/value/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/encoder_layer_3/value/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/encoder_layer_3/attention_output/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/encoder_layer_3/attention_output/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/layer_normalization_10/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/layer_normalization_10/beta:0', 'dense_10/kernel:0', 'dense_10/bias:0', 'dense_11/kernel:0', 'dense_11/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/feed_forward_5/layer_normalization_11/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/feed_forward_5/layer_normalization_11/beta:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/encoder_layer_4/query/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/encoder_layer_4/query/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/encoder_layer_4/key/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/encoder_layer_4/key/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/encoder_layer_4/value/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/encoder_layer_4/value/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/encoder_layer_4/attention_output/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/encoder_layer_4/attention_output/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/layer_normalization_12/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/layer_normalization_12/beta:0', 'dense_12/kernel:0', 'dense_12/bias:0', 'dense_13/kernel:0', 'dense_13/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/feed_forward_6/layer_normalization_13/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/feed_forward_6/layer_normalization_13/beta:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/encoder_layer_5/query/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/encoder_layer_5/query/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/encoder_layer_5/key/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/encoder_layer_5/key/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/encoder_layer_5/value/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/encoder_layer_5/value/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/encoder_layer_5/attention_output/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/encoder_layer_5/attention_output/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/layer_normalization_14/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/layer_normalization_14/beta:0', 'dense_14/kernel:0', 'dense_14/bias:0', 'dense_15/kernel:0', 'dense_15/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/feed_forward_7/layer_normalization_15/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/feed_forward_7/layer_normalization_15/beta:0', 'hierarchical_transformer_encoder/detection_layer/kernel:0', 'hierarchical_transformer_encoder/detection_layer/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/encoder_layer_1/query/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/encoder_layer_1/query/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/encoder_layer_1/key/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/encoder_layer_1/key/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/encoder_layer_1/value/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/encoder_layer_1/value/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/encoder_layer_1/attention_output/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/encoder_layer_1/attention_output/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/layer_normalization_6/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/global_self_attention_3/layer_normalization_6/beta:0', 'dense_6/kernel:0', 'dense_6/bias:0', 'dense_7/kernel:0', 'dense_7/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/feed_forward_3/layer_normalization_7/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_3/feed_forward_3/layer_normalization_7/beta:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/encoder_layer_2/query/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/encoder_layer_2/query/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/encoder_layer_2/key/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/encoder_layer_2/key/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/encoder_layer_2/value/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/encoder_layer_2/value/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/encoder_layer_2/attention_output/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/encoder_layer_2/attention_output/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/layer_normalization_8/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/global_self_attention_4/layer_normalization_8/beta:0', 'dense_8/kernel:0', 'dense_8/bias:0', 'dense_9/kernel:0', 'dense_9/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/feed_forward_4/layer_normalization_9/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_4/feed_forward_4/layer_normalization_9/beta:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/encoder_layer_3/query/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/encoder_layer_3/query/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/encoder_layer_3/key/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/encoder_layer_3/key/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/encoder_layer_3/value/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/encoder_layer_3/value/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/encoder_layer_3/attention_output/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/encoder_layer_3/attention_output/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/layer_normalization_10/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/global_self_attention_5/layer_normalization_10/beta:0', 'dense_10/kernel:0', 'dense_10/bias:0', 'dense_11/kernel:0', 'dense_11/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/feed_forward_5/layer_normalization_11/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_5/feed_forward_5/layer_normalization_11/beta:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/encoder_layer_4/query/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/encoder_layer_4/query/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/encoder_layer_4/key/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/encoder_layer_4/key/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/encoder_layer_4/value/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/encoder_layer_4/value/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/encoder_layer_4/attention_output/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/encoder_layer_4/attention_output/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/layer_normalization_12/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/global_self_attention_6/layer_normalization_12/beta:0', 'dense_12/kernel:0', 'dense_12/bias:0', 'dense_13/kernel:0', 'dense_13/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/feed_forward_6/layer_normalization_13/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_6/feed_forward_6/layer_normalization_13/beta:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/encoder_layer_5/query/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/encoder_layer_5/query/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/encoder_layer_5/key/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/encoder_layer_5/key/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/encoder_layer_5/value/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/encoder_layer_5/value/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/encoder_layer_5/attention_output/kernel:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/encoder_layer_5/attention_output/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/layer_normalization_14/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/global_self_attention_7/layer_normalization_14/beta:0', 'dense_14/kernel:0', 'dense_14/bias:0', 'dense_15/kernel:0', 'dense_15/bias:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/feed_forward_7/layer_normalization_15/gamma:0', 'hierarchical_transformer_encoder/encoder_1/encoder_layer_7/feed_forward_7/layer_normalization_15/beta:0', 'hierarchical_transformer_encoder/detection_layer/kernel:0', 'hierarchical_transformer_encoder/detection_layer/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "2/2 [==============================] - 7s 456ms/step - loss: 9.1723 - acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 1s 415ms/step - loss: 9.1394 - acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 1s 423ms/step - loss: 9.2358 - acc: 3.9888e-04\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 1s 436ms/step - loss: 9.1375 - acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 1s 413ms/step - loss: 9.1604 - acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 1s 409ms/step - loss: 9.0806 - acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 1s 420ms/step - loss: 9.1588 - acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 1s 419ms/step - loss: 9.1983 - acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 1s 425ms/step - loss: 9.1237 - acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 1s 420ms/step - loss: 9.1086 - acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x70981ae9b430>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Test model",
   "id": "e5cadd1c41806fb9"
  },
  {
   "cell_type": "code",
   "source": [
    "test_output = model.predict([[input_sequences_np[:100], input_sentences_lengths_np[:100]],\n",
    "                             [character_level_input_sequences_np[:100], input_words_lengths_np[:100]]])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T14:12:39.753315Z",
     "start_time": "2024-04-06T14:12:38.179503Z"
    }
   },
   "id": "97fb992fbe1f2992",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape của word_embedding_outputs: (None, 40, 128)\n",
      "Shape của correction_output: (None, 40, 10000)\n",
      "Shape của detection_output: (None, 40)\n",
      "4/4 [==============================] - 1s 56ms/step\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "for sentence in test_output[:100]:\n",
    "    out = ''\n",
    "    for word in sentence:\n",
    "        index = tf.argmax(word, axis=0).numpy()\n",
    "        word_str = word_level_tokenizer.index_word.get(index)\n",
    "        if word_str is not None:\n",
    "            out += word_str + ' '\n",
    "        else:\n",
    "            out += '<UNK> '\n",
    "    print(out)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T14:12:39.930380Z",
     "start_time": "2024-04-06T14:12:39.755302Z"
    }
   },
   "id": "c63689e16ef959dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<UNK> <UNK> <UNK> <UNK> <UNK> do <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> do <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> do <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> do <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> do <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> điểm <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> do <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> do <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> điểm <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> do <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> do do <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> do <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> do <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> do <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> do <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> do <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> do <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> do do <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> do <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> do <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> do <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> do <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> do <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> do <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> do <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> do <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> do <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> điểm do <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> do <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> do <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> do <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> do <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> do <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> do <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n",
      "<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> \n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T14:12:49.359360Z",
     "start_time": "2024-04-06T14:12:39.931550Z"
    }
   },
   "cell_type": "code",
   "source": "model.save('model.tf')",
   "id": "ba3e76255182823a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape của word_embedding_outputs: (None, 40, 128)\n",
      "Shape của correction_output: (None, 40, 10000)\n",
      "Shape của detection_output: (None, 40)\n",
      "Shape của word_embedding_outputs: (None, 40, 128)\n",
      "Shape của correction_output: (None, 40, 10000)\n",
      "Shape của detection_output: (None, 40)\n",
      "Shape của word_embedding_outputs: (None, 40, 128)\n",
      "Shape của correction_output: (None, 40, 10000)\n",
      "Shape của detection_output: (None, 40)\n",
      "INFO:tensorflow:Assets written to: model.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.tf/assets\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T14:12:53.147988Z",
     "start_time": "2024-04-06T14:12:49.362097Z"
    }
   },
   "cell_type": "code",
   "source": "loaded_model = tf.keras.models.load_model('model.tf', custom_objects={'CustomSchedule': CustomSchedule})",
   "id": "2c429e3bdb1c3a2d",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown loss function: 'custom_loss'. Please ensure you are using a `keras.utils.custom_object_scope` and that this object is included in the scope. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m loaded_model \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodels\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmodel.tf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mCustomSchedule\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mCustomSchedule\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/keras/src/saving/saving_api.py:238\u001B[0m, in \u001B[0;36mload_model\u001B[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001B[0m\n\u001B[1;32m    230\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m saving_lib\u001B[38;5;241m.\u001B[39mload_model(\n\u001B[1;32m    231\u001B[0m         filepath,\n\u001B[1;32m    232\u001B[0m         custom_objects\u001B[38;5;241m=\u001B[39mcustom_objects,\n\u001B[1;32m    233\u001B[0m         \u001B[38;5;28mcompile\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mcompile\u001B[39m,\n\u001B[1;32m    234\u001B[0m         safe_mode\u001B[38;5;241m=\u001B[39msafe_mode,\n\u001B[1;32m    235\u001B[0m     )\n\u001B[1;32m    237\u001B[0m \u001B[38;5;66;03m# Legacy case.\u001B[39;00m\n\u001B[0;32m--> 238\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlegacy_sm_saving_lib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    239\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_objects\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mcompile\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mcompile\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    240\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/keras/src/saving/legacy/serialization.py:537\u001B[0m, in \u001B[0;36mdeserialize_keras_object\u001B[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001B[0m\n\u001B[1;32m    535\u001B[0m     obj \u001B[38;5;241m=\u001B[39m module_objects\u001B[38;5;241m.\u001B[39mget(object_name)\n\u001B[1;32m    536\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m obj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 537\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    538\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnknown \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mprintable_module_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mobject_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    539\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease ensure you are using a \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    540\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`keras.utils.custom_object_scope` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    541\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mand that this object is included in the scope. See \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    542\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://www.tensorflow.org/guide/keras/save_and_serialize\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    543\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m#registering_the_custom_object for details.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    544\u001B[0m         )\n\u001B[1;32m    546\u001B[0m \u001B[38;5;66;03m# Classes passed by name are instantiated with no args, functions are\u001B[39;00m\n\u001B[1;32m    547\u001B[0m \u001B[38;5;66;03m# returned as-is.\u001B[39;00m\n\u001B[1;32m    548\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tf_inspect\u001B[38;5;241m.\u001B[39misclass(obj):\n",
      "\u001B[0;31mValueError\u001B[0m: Unknown loss function: 'custom_loss'. Please ensure you are using a `keras.utils.custom_object_scope` and that this object is included in the scope. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details."
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "loaded_model.predict([[input_sequences_np[:100], input_sentences_lengths_np[:100]],\n",
    "                      [character_level_input_sequences_np[:100], input_words_lengths_np[:100]]])"
   ],
   "id": "1cbfb444397f6084",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
